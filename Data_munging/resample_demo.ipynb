{"cells":[{"cell_type":"markdown","source":["## Overview:\nComparing **interpolation** between pandas UDF and pure spark sql"],"metadata":{}},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\n\nimport pyspark.sql.functions as f\nfrom pyspark.sql import Window\nfrom pyspark.sql.functions import pandas_udf\nfrom pyspark.sql.functions import PandasUDFType\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["@pandas_udf(\"group string, num0 long, num1 long, date date, exist string\", functionType=PandasUDFType.GROUPED_MAP)\ndef resampler(df):\n    '''\n    Resamples date and interpolates the rest of the columns.\n    '''\n    \n    # sets the data column as the index and resamples by day\n    result = (df.set_index(\n        pd.to_datetime(df['date'])).resample(\"24H\").last().drop(\"date\", axis=1).reset_index())  \n    result[\"exist\"] = np.where(result['exist'].isnull(), \"false\", \"true\")\n    # backfills object types and interpolates the rest\n    result = result.apply(lambda x: x.bfill() if x.dtype.kind in 'O' else x.interpolate())\n    \n    return result"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["df = pd.DataFrame({\"group\": [\"apple\", \"apple\", \"apple\", \"banana\", \"banana\", \"cat\", \"cat\", \"cat\"],\n                   \"num0\": [3, 3, 5, 1, 2, 3, 3, 5],\n                   \"num1\": [1000, 1000, 2000, 30, 10, 1000, 1000, 2000],\n                   \"date\": [\"2017-01-01\", \"2017-01-03\", \"2017-01-05\", \"2018-01-01\", \"2018-01-08\",\"2017-01-01\", \"2017-01-02\", \"2017-01-05\"],\n                   \"exist\": [\"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\", \"true\"]\n                  })\n\ndf = spark.createDataFrame(df).withColumn(\"date\", f.col(\"date\").cast(\"date\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["display(df)"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["### Pure Spark SQL Method"],"metadata":{}},{"cell_type":"code","source":["# Return the min and max Dates per group\ndf_group = (\n    df\n    .groupby('group')\n    .agg(f.min('date').alias('start'), f.max('date').alias('end'))\n)\n# Take the difference in days between the max and min dates then fill in that may days per group\ndf_resample = (\n    df_group\n    .withColumn('diffDays', f.datediff('end', 'start'))\n    .withColumn('repeat', f.expr(\"split(repeat(',', diffDays), ',')\"))\n    .select('*', f.posexplode('repeat').alias('date', 'val'))\n    .drop('repeat', 'val', 'diffDays')\n    .withColumn('date', f.expr('date_add(start, date)'))\n    .drop('start', 'end')\n)\ndf_merge = (\n    df_resample\n    .join(df, on=['group', 'date'], how='left')\n    .orderBy(['group', 'date'])\n    .withColumn('id', f.when(f.col('exist').isNotNull(), f.monotonically_increasing_id()))\n    .withColumn('exist', f.when(f.col('exist').isNull(), 'false').otherwise('true'))\n)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# Set the window functions for Interpolation\nw1 = Window.partitionBy(\"group\").orderBy(\"date\")\nw2 = Window.partitionBy(\"group_id\").orderBy(\"date\")\nw3 = Window.partitionBy(\"group_id\")\nw4 = Window.partitionBy(\"group\").orderBy(\"id\")\n\n# Set the columns needed to interpolate\nresult = df_merge \\\n    .withColumn(\"group_id\", f.last(f.col(\"id\"), ignorenulls=True).over(w1)) \\\n    .withColumn(\"i\", f.row_number().over(w2) - 1) \\\n    .withColumn(\"dx\", f.max(f.col(\"i\") + 1).over(w3))\n\nfor name in [\"num0\", \"num1\"]:\n  result = result.withColumn(\"next_value_{}\".format(name), f.lead(name, 1).over(w4))\n\n# Interpolate the columns and drop the created variables\nfor name in [\"num0\", \"num1\"]:\n  result = result \\\n        .withColumn(\"value0_{}\".format(name), f.first(name).over(w2))\\\n        .withColumn(\"dy_{}\".format(name), f.first(f.col(\"next_value_{}\".format(name)) - f.col(name)).over(w2))\\\n        .withColumn(\"{}\".format(name), \n        f.when(f.isnull(\"{}\".format(name)), \n               (f.col(\"value0_{}\".format(name)) + f.col(\"i\") * f.col(\"dy_{}\".format(name)) / f.col(\"dx\")).cast(result.schema[\"{}\".format(name)].dataType)) \\\n               .otherwise(f.col(name))) \\\n        .withColumn(\"{}\".format(name), f.last(\"{}\".format(name), ignorenulls=True).over(w1)) \\\n        .drop(\"next_value_{}\".format(name), \"value0_{}\".format(name), \"dy_{}\".format(name), \"value0_{}\".format(name))\n\nresult = result \\\n  .drop(\"next_position\", \"group_id\", \"i\", \"id\", \"dx\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8},{"cell_type":"code","source":["display(result)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>group</th><th>date</th><th>num0</th><th>num1</th><th>exist</th></tr></thead><tbody><tr><td>apple</td><td>2017-01-01</td><td>3</td><td>1000</td><td>true</td></tr><tr><td>apple</td><td>2017-01-02</td><td>3</td><td>1000</td><td>false</td></tr><tr><td>apple</td><td>2017-01-03</td><td>3</td><td>1000</td><td>true</td></tr><tr><td>apple</td><td>2017-01-04</td><td>4</td><td>1500</td><td>false</td></tr><tr><td>apple</td><td>2017-01-05</td><td>5</td><td>2000</td><td>true</td></tr><tr><td>cat</td><td>2017-01-01</td><td>3</td><td>1000</td><td>true</td></tr><tr><td>cat</td><td>2017-01-02</td><td>3</td><td>1000</td><td>true</td></tr><tr><td>cat</td><td>2017-01-03</td><td>3</td><td>1333</td><td>false</td></tr><tr><td>cat</td><td>2017-01-04</td><td>4</td><td>1666</td><td>false</td></tr><tr><td>cat</td><td>2017-01-05</td><td>5</td><td>2000</td><td>true</td></tr><tr><td>banana</td><td>2018-01-01</td><td>1</td><td>30</td><td>true</td></tr><tr><td>banana</td><td>2018-01-02</td><td>1</td><td>27</td><td>false</td></tr><tr><td>banana</td><td>2018-01-03</td><td>1</td><td>24</td><td>false</td></tr><tr><td>banana</td><td>2018-01-04</td><td>1</td><td>21</td><td>false</td></tr><tr><td>banana</td><td>2018-01-05</td><td>1</td><td>18</td><td>false</td></tr><tr><td>banana</td><td>2018-01-06</td><td>1</td><td>15</td><td>false</td></tr><tr><td>banana</td><td>2018-01-07</td><td>1</td><td>12</td><td>false</td></tr><tr><td>banana</td><td>2018-01-08</td><td>2</td><td>10</td><td>true</td></tr></tbody></table></div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["### Using Pandas UDF Method"],"metadata":{}},{"cell_type":"code","source":["test_pandas_udf = df.groupby([\"group\"]).apply(resampler)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":11},{"cell_type":"code","source":["display(test_pandas_udf)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>group</th><th>num0</th><th>num1</th><th>date</th><th>exist</th></tr></thead><tbody><tr><td>apple</td><td>3</td><td>1000</td><td>2017-01-01</td><td>true</td></tr><tr><td>apple</td><td>3</td><td>1000</td><td>2017-01-02</td><td>false</td></tr><tr><td>apple</td><td>3</td><td>1000</td><td>2017-01-03</td><td>true</td></tr><tr><td>apple</td><td>4</td><td>1500</td><td>2017-01-04</td><td>false</td></tr><tr><td>apple</td><td>5</td><td>2000</td><td>2017-01-05</td><td>true</td></tr><tr><td>cat</td><td>3</td><td>1000</td><td>2017-01-01</td><td>true</td></tr><tr><td>cat</td><td>3</td><td>1000</td><td>2017-01-02</td><td>true</td></tr><tr><td>cat</td><td>3</td><td>1333</td><td>2017-01-03</td><td>false</td></tr><tr><td>cat</td><td>4</td><td>1666</td><td>2017-01-04</td><td>false</td></tr><tr><td>cat</td><td>5</td><td>2000</td><td>2017-01-05</td><td>true</td></tr><tr><td>banana</td><td>1</td><td>30</td><td>2018-01-01</td><td>true</td></tr><tr><td>banana</td><td>1</td><td>27</td><td>2018-01-02</td><td>false</td></tr><tr><td>banana</td><td>1</td><td>24</td><td>2018-01-03</td><td>false</td></tr><tr><td>banana</td><td>1</td><td>21</td><td>2018-01-04</td><td>false</td></tr><tr><td>banana</td><td>1</td><td>18</td><td>2018-01-05</td><td>false</td></tr><tr><td>banana</td><td>1</td><td>15</td><td>2018-01-06</td><td>false</td></tr><tr><td>banana</td><td>1</td><td>12</td><td>2018-01-07</td><td>false</td></tr><tr><td>banana</td><td>2</td><td>10</td><td>2018-01-08</td><td>true</td></tr></tbody></table></div>"]}}],"execution_count":12},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":13}],"metadata":{"name":"resample_demo","notebookId":2139870513491241},"nbformat":4,"nbformat_minor":0}
